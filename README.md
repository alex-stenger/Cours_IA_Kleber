## **FR :**

Ce dépot contient les slides ainsi que le code que j'ai utilisé lors de mes cours magistraux sur l'Intelligence Artificielle en 2ème année de CPGE scientifiques au Lycée Kléber à Strabourg.

À travers ce cours, j'ai choisi une approche par l'analyse (contrairement aux approches probabilistes de Murphy que je cite plus bas, à l'approche algèbrique du Deep Learning book de Goodfellow, ou encore via la théorie de l'information). Elle me semblait la plus adaptée aux élèves de classes préparatoire.

Ce cours se construit autour d'un premier exemple de régression linéaire réalisée grâce à la descente de gradient. Cette première approche très simpliste permet aux étudiants de saisir le fonctionnement de la descente de gradient, ainsi que de revenir sur la notion fondamentale de convexité d'une fonction, ici, dans un espace de petite dimension toujours dans le but de faciliter la compréhension.

La descente de gradient est ensuite généralisée à plus grande dimension, pour illuster que c'est une méthode très générique et réutilisable dans d'autres situations. 

Une fois cette notion bien comprise par les étudiants, le cours introduit les réseaux de neuronnes. Pour cela, j'ai décidé une approche plus mathématique et abstraite qui parle points par points de l'architectures des réseaux, de la notion de propagation, de backpropagation et du fonctionnement spécifique de la descente de gradient pour les réseaux de neurones. Pour cela, je reprends en grande partie les démonstration de cette très précise et explicative réference : http://neuralnetworksanddeeplearning.com/chap2.html

Enfin, ce cours aborde également les notions élémentaires d'apprentissage que sont la phase d'entraînement, de test, les biais, le sur-apprentissage, le sous-apprentissage, les notions de supervisé et non supervisé ou encore la différence entre Classification et régression etc etc...

Les références sont indiquées tout au long des slides, on peut néanmoins nommé ce bouquin très utile, bien que l'approche soit complétement différente : Murphy, K. P. (2012). Machine learning: a probabilistic perspective. MIT press.


## **EN :**
